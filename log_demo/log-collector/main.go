package main

import (
	"bufio"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"strings"
	"time"

	"github.com/IBM/sarama"
	"github.com/fsnotify/fsnotify"
)

// FileCollectorLogEntry æ–‡ä»¶é‡‡é›†å™¨æ—¥å¿—æ¡ç›®
type FileCollectorLogEntry struct {
	Timestamp    string            `json:"timestamp"`
	Level        string            `json:"level"`
	Service      string            `json:"service"`
	Message      string            `json:"message"`
	FileName     string            `json:"file_name"`
	FilePath     string            `json:"file_path"`
	LineNumber   int               `json:"line_number"`
	RequestID    string            `json:"request_id"`
	OriginalLine string            `json:"original_line"`
	Metadata     map[string]string `json:"metadata"`
	CollectedAt  string            `json:"collected_at"`

	// æ¸…æ´—åçš„æ•°æ®
	CleanedMessage  string            `json:"cleaned_message"`
	ExtractedFields map[string]string `json:"extracted_fields"`
	ProcessedAt     string            `json:"processed_at"`
	DataQuality     string            `json:"data_quality"`
}

// PythonDataCleaner æ¨¡æ‹ŸPythonæ•°æ®æ¸…æ´—å™¨
type PythonDataCleaner struct{}

// NewPythonDataCleaner åˆ›å»ºæ•°æ®æ¸…æ´—å™¨
func NewPythonDataCleaner() *PythonDataCleaner {
	return &PythonDataCleaner{}
}

// CleanData æ¨¡æ‹ŸPythonæ•°æ®æ¸…æ´—é€»è¾‘
func (cleaner *PythonDataCleaner) CleanData(logEntry *FileCollectorLogEntry) {
	log.Printf("ğŸ [Pythonæ¸…æ´—] å¤„ç†æ—¥å¿—: %s", logEntry.RequestID)

	// æ¨¡æ‹Ÿæ•°æ®æ¸…æ´—å»¶è¿Ÿ
	time.Sleep(time.Millisecond * 50)

	// æ¸…æ´—æ¶ˆæ¯æ–‡æœ¬
	cleanedMessage := cleaner.cleanMessage(logEntry.Message)
	logEntry.CleanedMessage = cleanedMessage

	// æå–å…³é”®å­—æ®µ
	logEntry.ExtractedFields = cleaner.extractFields(logEntry.Message, logEntry.Service)

	// è®¾ç½®å¤„ç†æ—¶é—´
	logEntry.ProcessedAt = time.Now().Format(time.RFC3339)

	// è¯„ä¼°æ•°æ®è´¨é‡
	logEntry.DataQuality = cleaner.assessDataQuality(logEntry)

	log.Printf("âœ… [Pythonæ¸…æ´—] å®Œæˆ: %s -> %s", logEntry.Message[:min(30, len(logEntry.Message))], cleanedMessage[:min(30, len(cleanedMessage))])
}

// cleanMessage æ¸…æ´—æ¶ˆæ¯æ–‡æœ¬
func (cleaner *PythonDataCleaner) cleanMessage(message string) string {
	// ç§»é™¤å¤šä½™ç©ºæ ¼
	cleaned := regexp.MustCompile(`\s+`).ReplaceAllString(message, " ")

	// ç§»é™¤ç‰¹æ®Šå­—ç¬¦
	cleaned = regexp.MustCompile(`[^\w\s\.:\/=\-]`).ReplaceAllString(cleaned, "")

	// æ ‡å‡†åŒ–HTTPçŠ¶æ€ç æè¿°
	cleaned = regexp.MustCompile(`HTTP/1\.1\s+(\d+)`).ReplaceAllString(cleaned, "HTTP_$1")

	// æ ‡å‡†åŒ–æ—¶é—´æ ¼å¼
	cleaned = regexp.MustCompile(`(\d+)ms`).ReplaceAllString(cleaned, "${1}_milliseconds")

	return strings.TrimSpace(cleaned)
}

// extractFields æå–å…³é”®å­—æ®µ
func (cleaner *PythonDataCleaner) extractFields(message, service string) map[string]string {
	fields := make(map[string]string)

	switch service {
	case "nginx":
		// æå–HTTPç›¸å…³å­—æ®µ
		if matches := regexp.MustCompile(`(GET|POST|PUT|DELETE)\s+([^\s]+)`).FindStringSubmatch(message); len(matches) >= 3 {
			fields["http_method"] = matches[1]
			fields["http_path"] = matches[2]
		}
		if matches := regexp.MustCompile(`HTTP/1\.1\s+(\d+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["http_status"] = matches[1]
		}
		if matches := regexp.MustCompile(`(\d+\.\d+)$`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["response_time"] = matches[1]
		}

	case "application":
		// æå–ä¸šåŠ¡å­—æ®µ
		if matches := regexp.MustCompile(`userId=(\w+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["user_id"] = matches[1]
		}
		if matches := regexp.MustCompile(`orderId=(\w+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["order_id"] = matches[1]
		}
		if matches := regexp.MustCompile(`amount=([0-9.]+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["amount"] = matches[1]
		}

	case "database":
		// æå–æ•°æ®åº“å­—æ®µ
		if matches := regexp.MustCompile(`table=(\w+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["table_name"] = matches[1]
		}
		if matches := regexp.MustCompile(`duration=(\d+)ms`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["query_duration"] = matches[1]
		}
		if matches := regexp.MustCompile(`rows=(\d+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["rows_affected"] = matches[1]
		}

	case "security":
		// æå–å®‰å…¨å­—æ®µ
		if matches := regexp.MustCompile(`ip=([0-9.]+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["ip_address"] = matches[1]
		}
		if matches := regexp.MustCompile(`user=(\w+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["username"] = matches[1]
		}
		if matches := regexp.MustCompile(`result=(\w+)`).FindStringSubmatch(message); len(matches) >= 2 {
			fields["auth_result"] = matches[1]
		}
	}

	return fields
}

// assessDataQuality è¯„ä¼°æ•°æ®è´¨é‡
func (cleaner *PythonDataCleaner) assessDataQuality(logEntry *FileCollectorLogEntry) string {
	score := 100

	// æ£€æŸ¥å¿…è¦å­—æ®µ
	if logEntry.Timestamp == "" {
		score -= 20
	}
	if logEntry.Level == "" {
		score -= 15
	}
	if logEntry.Message == "" {
		score -= 30
	}

	// æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
	if len(logEntry.ExtractedFields) == 0 {
		score -= 10
	}

	// æ£€æŸ¥æ¶ˆæ¯é•¿åº¦
	if len(logEntry.Message) < 10 {
		score -= 10
	}

	if score >= 90 {
		return "HIGH"
	} else if score >= 70 {
		return "MEDIUM"
	} else {
		return "LOW"
	}
}

// FileCollectorKafkaProducer æ–‡ä»¶é‡‡é›†å™¨ä¸“ç”¨çš„Kafkaç”Ÿäº§è€…
type FileCollectorKafkaProducer struct {
	producer sarama.SyncProducer
}

// NewFileCollectorKafkaProducer åˆ›å»ºæ–‡ä»¶é‡‡é›†å™¨Kafkaç”Ÿäº§è€…
func NewFileCollectorKafkaProducer(brokers []string) (*FileCollectorKafkaProducer, error) {
	config := sarama.NewConfig()
	config.Producer.Return.Successes = true
	config.Producer.RequiredAcks = sarama.WaitForAll // ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ç¡®è®¤
	config.Producer.Retry.Max = 5                    // é‡è¯•æ¬¡æ•°
	config.Producer.Partitioner = sarama.NewHashPartitioner
	config.Producer.Idempotent = true // å¹‚ç­‰æ€§ï¼Œé˜²æ­¢é‡å¤å‘é€
	config.Net.MaxOpenRequests = 1

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºKafkaç”Ÿäº§è€…å¤±è´¥: %v", err)
	}

	return &FileCollectorKafkaProducer{producer: producer}, nil
}

// SendMessage å‘é€æ¶ˆæ¯åˆ°Kafka
func (kp *FileCollectorKafkaProducer) SendMessage(topic string, key string, value []byte) error {
	msg := &sarama.ProducerMessage{
		Topic: topic,
		Key:   sarama.StringEncoder(key),
		Value: sarama.ByteEncoder(value),
	}

	partition, offset, err := kp.producer.SendMessage(msg)
	if err != nil {
		return fmt.Errorf("å‘é€æ¶ˆæ¯å¤±è´¥: %v", err)
	}

	log.Printf("ğŸ“¤ æ¶ˆæ¯å‘é€æˆåŠŸ: topic=%s, partition=%d, offset=%d", topic, partition, offset)
	return nil
}

// Close å…³é—­ç”Ÿäº§è€…
func (kp *FileCollectorKafkaProducer) Close() error {
	return kp.producer.Close()
}

// FileCollector æ–‡ä»¶é‡‡é›†å™¨
type FileCollector struct {
	kafka         *FileCollectorKafkaProducer
	watcher       *fsnotify.Watcher
	logDir        string
	topic         string
	filePositions map[string]int64
	dataCleaner   *PythonDataCleaner
}

// LogParser æ—¥å¿—è§£æå™¨
type LogParser struct {
	logPattern *regexp.Regexp
	serviceMap map[string]string
}

// NewLogParser åˆ›å»ºæ—¥å¿—è§£æå™¨
func NewLogParser() *LogParser {
	// åŒ¹é…æ—¥å¿—æ ¼å¼: [timestamp] [level] [request_id] message
	pattern := regexp.MustCompile(`\[([^\]]+)\]\s*\[([^\]]+)\]\s*\[([^\]]+)\]\s*(.+)`)

	serviceMap := map[string]string{
		"nginx.log":       "nginx",
		"application.log": "application",
		"database.log":    "database",
		"security.log":    "security",
	}

	return &LogParser{
		logPattern: pattern,
		serviceMap: serviceMap,
	}
}

// ParseLogLine è§£ææ—¥å¿—è¡Œ
func (p *LogParser) ParseLogLine(line, fileName string, lineNumber int) (*FileCollectorLogEntry, error) {
	matches := p.logPattern.FindStringSubmatch(line)
	if len(matches) != 5 {
		// å¦‚æœä¸åŒ¹é…æ ‡å‡†æ ¼å¼ï¼Œä½œä¸ºæ™®é€šæ¶ˆæ¯å¤„ç†
		return &FileCollectorLogEntry{
			Timestamp:    time.Now().Format(time.RFC3339),
			Level:        "INFO",
			Service:      p.getServiceFromFileName(fileName),
			Message:      strings.TrimSpace(line),
			FileName:     fileName,
			LineNumber:   lineNumber,
			RequestID:    fmt.Sprintf("file_%d_%d", time.Now().Unix(), lineNumber),
			OriginalLine: line,
			CollectedAt:  time.Now().Format(time.RFC3339),
			Metadata:     make(map[string]string),
		}, nil
	}

	// è§£ææ—¶é—´æˆ³
	timestamp := matches[1]
	if parsedTime, err := time.Parse("2006-01-02 15:04:05", timestamp); err == nil {
		timestamp = parsedTime.Format(time.RFC3339)
	}

	// æå–å…ƒæ•°æ®
	metadata := p.extractMetadata(matches[4])

	return &FileCollectorLogEntry{
		Timestamp:    timestamp,
		Level:        matches[2],
		Service:      p.getServiceFromFileName(fileName),
		Message:      matches[4],
		FileName:     fileName,
		LineNumber:   lineNumber,
		RequestID:    matches[3],
		OriginalLine: line,
		CollectedAt:  time.Now().Format(time.RFC3339),
		Metadata:     metadata,
	}, nil
}

// getServiceFromFileName ä»æ–‡ä»¶åè·å–æœåŠ¡å
func (p *LogParser) getServiceFromFileName(fileName string) string {
	if service, exists := p.serviceMap[fileName]; exists {
		return service
	}
	return "unknown"
}

// extractMetadata æå–å…ƒæ•°æ®
func (p *LogParser) extractMetadata(message string) map[string]string {
	metadata := make(map[string]string)

	// æå–é”®å€¼å¯¹ (key=value æ ¼å¼)
	kvPattern := regexp.MustCompile(`(\w+)=([^\s]+)`)
	matches := kvPattern.FindAllStringSubmatch(message, -1)

	for _, match := range matches {
		if len(match) == 3 {
			metadata[match[1]] = match[2]
		}
	}

	return metadata
}

// NewFileCollector åˆ›å»ºæ–‡ä»¶é‡‡é›†å™¨
func NewFileCollector(logDir, topic string, kafka *FileCollectorKafkaProducer) (*FileCollector, error) {
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return nil, err
	}

	return &FileCollector{
		kafka:         kafka,
		watcher:       watcher,
		logDir:        logDir,
		topic:         topic,
		filePositions: make(map[string]int64),
		dataCleaner:   NewPythonDataCleaner(),
	}, nil
}

// Start å¯åŠ¨æ–‡ä»¶é‡‡é›†
func (fc *FileCollector) Start() error {
	parser := NewLogParser()

	// æ·»åŠ ç›®å½•ç›‘æ§
	err := fc.watcher.Add(fc.logDir)
	if err != nil {
		return err
	}

	log.Printf("å¼€å§‹ç›‘æ§ç›®å½•: %s", fc.logDir)

	// é¦–æ¬¡è¯»å–æ‰€æœ‰ç°æœ‰æ–‡ä»¶
	err = fc.readExistingFiles(parser)
	if err != nil {
		log.Printf("è¯»å–ç°æœ‰æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// ç›‘æ§æ–‡ä»¶å˜åŒ–
	go func() {
		for {
			select {
			case event, ok := <-fc.watcher.Events:
				if !ok {
					return
				}

				if event.Op&fsnotify.Write == fsnotify.Write {
					log.Printf("æ–‡ä»¶å˜åŒ–: %s", event.Name)
					fc.processFileChange(event.Name, parser)
				}

			case err, ok := <-fc.watcher.Errors:
				if !ok {
					return
				}
				log.Printf("ç›‘æ§é”™è¯¯: %v", err)
			}
		}
	}()

	return nil
}

// readExistingFiles è¯»å–ç°æœ‰æ–‡ä»¶
func (fc *FileCollector) readExistingFiles(parser *LogParser) error {
	files, err := os.ReadDir(fc.logDir)
	if err != nil {
		return err
	}

	for _, file := range files {
		if file.IsDir() || !strings.HasSuffix(file.Name(), ".log") {
			continue
		}

		filePath := filepath.Join(fc.logDir, file.Name())
		log.Printf("å¤„ç†ç°æœ‰æ–‡ä»¶: %s", filePath)

		err := fc.processFile(filePath, parser)
		if err != nil {
			log.Printf("å¤„ç†æ–‡ä»¶å¤±è´¥ %s: %v", filePath, err)
		}
	}

	return nil
}

// processFileChange å¤„ç†æ–‡ä»¶å˜åŒ–
func (fc *FileCollector) processFileChange(filePath string, parser *LogParser) {
	if !strings.HasSuffix(filePath, ".log") {
		return
	}

	err := fc.processFile(filePath, parser)
	if err != nil {
		log.Printf("å¤„ç†æ–‡ä»¶å˜åŒ–å¤±è´¥ %s: %v", filePath, err)
	}
}

// processFile å¤„ç†å•ä¸ªæ–‡ä»¶
func (fc *FileCollector) processFile(filePath string, parser *LogParser) error {
	file, err := os.Open(filePath)
	if err != nil {
		return err
	}
	defer file.Close()

	// è·å–æ–‡ä»¶å½“å‰ä½ç½®
	fileName := filepath.Base(filePath)
	lastPosition := fc.filePositions[filePath]

	// å®šä½åˆ°ä¸Šæ¬¡è¯»å–çš„ä½ç½®
	_, err = file.Seek(lastPosition, 0)
	if err != nil {
		return err
	}

	scanner := bufio.NewScanner(file)
	lineNumber := int(lastPosition) // ç®€åŒ–çš„è¡Œå·è®¡ç®—

	for scanner.Scan() {
		line := scanner.Text()
		if strings.TrimSpace(line) == "" {
			continue
		}

		lineNumber++

		// è§£ææ—¥å¿—è¡Œ
		logEntry, err := parser.ParseLogLine(line, fileName, lineNumber)
		if err != nil {
			log.Printf("è§£ææ—¥å¿—è¡Œå¤±è´¥: %v", err)
			continue
		}

		logEntry.FilePath = filePath

		// ğŸ æ•°æ®æ¸…æ´—å¤„ç†
		fc.dataCleaner.CleanData(logEntry)

		// å‘é€åˆ°Kafka
		err = fc.sendToKafka(logEntry)
		if err != nil {
			log.Printf("å‘é€åˆ°Kafkaå¤±è´¥: %v", err)
			continue
		}

		log.Printf("é‡‡é›†æ—¥å¿—: %s [%s] %s [è´¨é‡:%s]", logEntry.Service, logEntry.Level, logEntry.CleanedMessage[:min(40, len(logEntry.CleanedMessage))], logEntry.DataQuality)
	}

	// æ›´æ–°æ–‡ä»¶ä½ç½®
	currentPosition, _ := file.Seek(0, 1)
	fc.filePositions[filePath] = currentPosition

	return scanner.Err()
}

// sendToKafka å‘é€åˆ°Kafka
func (fc *FileCollector) sendToKafka(logEntry *FileCollectorLogEntry) error {
	jsonData, err := json.Marshal(logEntry)
	if err != nil {
		return err
	}

	return fc.kafka.SendMessage(fc.topic, logEntry.RequestID, jsonData)
}

// Close å…³é—­é‡‡é›†å™¨
func (fc *FileCollector) Close() error {
	return fc.watcher.Close()
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

func main() {
	// åˆ›å»ºKafkaç”Ÿäº§è€…
	producer, err := NewFileCollectorKafkaProducer([]string{"localhost:9092"})
	if err != nil {
		log.Fatalf("âŒ åˆ›å»ºKafkaç”Ÿäº§è€…å¤±è´¥: %v", err)
	}
	defer producer.Close()

	// åˆ›å»ºæ–‡ä»¶é‡‡é›†å™¨
	logDir := "/root/A-log/log-generator/logs"
	collector, err := NewFileCollector(logDir, "log-data", producer)
	if err != nil {
		log.Fatalf("âŒ åˆ›å»ºæ–‡ä»¶é‡‡é›†å™¨å¤±è´¥: %v", err)
	}
	defer collector.Close()

	log.Println("========================================")
	log.Println("ğŸ“‚ æ–‡ä»¶æ—¥å¿—é‡‡é›†å™¨å¯åŠ¨")
	log.Println("ğŸ é›†æˆPythonæ•°æ®æ¸…æ´—æ¨¡å—")
	log.Println("========================================")
	log.Printf("ğŸ“ ç›‘æ§ç›®å½•: %s", logDir)
	log.Printf("ğŸ“¤ Kafkaä¸»é¢˜: log-data")
	log.Printf("ğŸ“‹ æ”¯æŒæ–‡ä»¶: *.log")
	log.Printf("ğŸ§¹ æ•°æ®æ¸…æ´—: å¯ç”¨")
	log.Println("========================================")

	// å¯åŠ¨é‡‡é›†
	err = collector.Start()
	if err != nil {
		log.Fatalf("âŒ å¯åŠ¨é‡‡é›†å¤±è´¥: %v", err)
	}

	log.Println("ğŸš€ æ–‡ä»¶é‡‡é›†å™¨å·²å¯åŠ¨ï¼ŒæŒ‰ Ctrl+C åœæ­¢...")

	// ä¿æŒç¨‹åºè¿è¡Œ
	select {}
}
